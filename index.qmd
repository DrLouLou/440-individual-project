---
title: 440-individual-project
authors:
  - name: Louis Choo-Choy
    affiliation: Duke University
    roles: writing
    corresponding: true
bibliography: references.bib
---

## Packages

```{r}
library(tidyverse)
library(sf)
library(dplyr)
library(viridis)
library(spdep)  
library(ggplot2)
library(spatialreg)
```

## Introduction and Data

We are interested in the relationship between perceived satisfaction with quality of life and length of time living in the Durham. This could be used as a measure of whether the living standards of Durham have improved over time. As secondary questions, we are interested in whether a resident being a renter or an owner affects this perceived satisfaction and whether the satisfaction of people living in the same neighborhood is independent of one another.\

Variables of relevance:

Q1. Satisfaction with Major Categories of Services Provided by the City and County

Q3. Level of Satisfaction with Items That Influence Perceptions of Durham

Q27. Approximately how many years have you lived in Durham?

Q30. Do you own or rent your current residence?

Zip

PAC (Partners Against Crime)

With respect to the spatial aspect of the data, we could potentially either use the Zip data to aggregate points together, or use the latitude and longitude data to map each point individually. But, ZIP codes are administrative, and two respondents in the same ZIP might actually live far apart (or two in adjacent ZIPs might live right next door). Using raw lat/long lets you define neighbors by real distance (e.g. everyone within 500 m or the 6 nearest neighbors), which directly captures spatial dependence at the respondent level.

Try to conduct spatial weight matrix with latitude and longitude and distance-based adjacency as the adjacency metric. If it's too computationally expensive, use Zip code or PAC zone (only 5 of them) and construct the spatial weight matrix using neighbor-based adjacency.

```{r}
resident_survey <- read_csv("data/resident_survey.csv")
```

## Cleaning

```{r}
resident_survey_cleaned <- resident_survey %>% 
  filter(!is.na(`Block Lon`), !is.na(`Block Lat`)) %>% 
  # convert micro-degrees → degrees
  mutate(
    Lon = `Block Lon` / 1e6,
    Lat = `Block Lat` / 1e6
  ) %>% 
  st_as_sf(coords = c("Lon","Lat"), crs = 4326) 

```

```{r}
resident_survey_cleaned <- resident_survey_cleaned %>% 
  rename(`years_live_durham` = `Q27  Approximately how many years have y`) %>% 
  rename(`own_rent` = `Q30  Do you own or rent your current res`) %>% 
  mutate(
    own_rent = factor(
      own_rent,
      levels = c(1, 2),
      labels = c("Own", "Rent")
    )
  )
```

```{r}
q1_cols <- grep("^Q1\\[\\d+\\]", names(resident_survey_cleaned), value=TRUE)
```

```{r}
resident_survey_cleaned <- resident_survey_cleaned %>%
  # 1) Convert all Q1[...] columns to numeric
  mutate(across(all_of(q1_cols), ~ as.numeric(as.character(.)))) %>%
  # 2) Compute the mean of those (ignoring NAs) via rowMeans
  mutate(Q1_mean = rowMeans(across(all_of(q1_cols)), na.rm = TRUE))
```

```{r}
durham_cnty <- st_read("data/Durham_County_boundary/Durham_County_Boundary.shp")
```

## Exploratory Data Analysis

```{r}
# Exploratory Point Map for Mean Satisfaction
ggplot() +
  geom_sf(data = durham_cnty,
          fill    = "grey95",
          color   = "grey40",
          size    = 0.5) +
  geom_sf(data = resident_survey_cleaned,
          aes(color = Q1_mean),
          size    = 1.2) +
  scale_color_viridis_c(name = "QOL Satisfaction") +
  labs(title = "Durham County + Survey Respondent Satisfaction") +
  theme_minimal()
```

```{r}
# Exploratory Point Map for Years Lived in Durham
ggplot() +
  geom_sf(data = durham_cnty,
          fill    = "grey95",
          color   = "grey40",
          size    = 0.5) +
  geom_sf(data = resident_survey_cleaned,
          aes(color = years_live_durham),
          size    = 1.2) +
  scale_color_viridis_c(name = "Years Lived in Durham") +
  labs(title = "Durham County + Years Lived in Durham") +
  theme_minimal()
```

```{r}
# Exploratory Point Map for Owners and Renters in Durham
ggplot() +
  geom_sf(data = durham_cnty,
          fill    = "grey95",
          color   = "grey40",
          size    = 0.5) +
  geom_sf(data = resident_survey_cleaned,
          aes(color = own_rent),
          size    = 1.2) +
  scale_color_viridis_d(name = "Renters or Owners in Durham") +
  labs(title = "Durham County + Renters or Owners in Durham") +
  theme_minimal()
```

From the map, it appears that the respondent locations are **very uneven**—a high‐density core around downtown and much sparser points out in the semi-rural north. That kind of density variation tends to **break** a fixed distance threshold (there will be rural points that have few or zero neighbors), whereas a k–NN graph will always give each point exactly “k” neighbors, keeping your weight matrix fully connected.

So, it makes more sense to use k-nearest neighbors. A common rule of thumb is *k* ≈ 6–10 for a few hundred points, which ensures each rural location still borrows strength from its nearest handful of neighbors, and each downtown point isn’t swamped with dozens.

## Methodology

```{r}
# determine hyper parameter k
```

```{r}
set.seed(123)  # for reproducibility

# 1. apply a tiny jitter to your survey points
survey_jit <- resident_survey_cleaned %>%
  st_jitter(amount = 1e-5)  

# 2. rebuild your coords and 6-NN on the jittered points
coords_jit <- st_coordinates(survey_jit)
knn6_jit   <- knearneigh(coords_jit, k = 6)
nb_knn     <- knn2nb(knn6_jit)

# 3. make it symmetric, then row-standardize
nb_sym   <- make.sym.nb(nb_knn)
lw_knn   <- nb2listw(nb_sym, style = "W")

# Confirm
summary(nb_sym)

```

```{r}
# Moran’s I on the raw outcome
# tells you if spatial autocorrelation exists.
moran_test_raw <- moran.test(
  survey_jit$Q1_mean,
  lw_knn
)
print(moran_test_raw)

```

-   The global Moran’s *I* is essentially zero and non-significant (p≈0.62), so there’s no evidence of clustering in **Q1_mean**. In practice that means a **standard OLS** will suffice.

```{r}
# Fit a non-spatial baseline

# OLS with your outcome Q1_mean, predictors years_live_durham and own_rent, plus any covariates
lm0 <- lm(
  # what other predictors to add? 
  Q1_mean ~ years_live_durham * own_rent,
  data = survey_jit
)
summary(lm0)
```

```{r}
# confirm the OLS residuals
moran.test(resid(lm0), lw_knn)

```

-   How to determine hyperparameter k?

-   Those warnings and the “Non-symmetric neighbours list” message are both down to the fact that you have **identical point coordinates** (multiple respondents geocoded to the same building-centroid), which breaks the k-NN algorithm and leads to one-way neighbour links.

-   Talk about the choice to do either jitter or aggregate for responses from the same location. chose to jitter because I don't want to lose data when aggregating.

Obtaining a shapefile of durham is not strictly necessary for computing the distance-based spatial weight matrix, but it is good for creating publication quality figures. Also, if we want to compare points to areal models like ZIP later on, this will make the comparison easier.

## Sources

1.  <https://live-durhamnc.opendata.arcgis.com/datasets/durham-county-boundary/explore?location=36.051924%2C-78.878990%2C9.91>
